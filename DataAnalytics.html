<html lang="vi">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">
    <meta name="docsearch:language" content="en">
    <title></title>

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-BmbxuPwQa2lc/FVzBcNJ7UAyJxM6wuqIj61tLrc4wSX0szH/Ev+nYRRuWlolflfl" crossorigin="anonymous">

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="./css/common.css">


</head>

<body class="fixed-nav" id="page-top">
    <div class="page-content-wrapper">
        <div class="container">
            <div class="row">
                <div class="col-md-2"></div>
                <div class="col-md-8">
                    <br>
                    <div class="accordion" id="accordionQuestion">
                        <div class="accordion-item">
                            <div class="accordion-header" id="heading-4888">
                                <div style="color: rgba(0, 0, 0, 0.8);" class="accordion-button" type="button"
                                    data-bs-toggle="collapse" data-bs-target="#collapse-4888" aria-expanded="true"
                                    aria-controls="collapse-4888">
                                    <div style="display: flex;flex-direction: row;justify-content: space-between;}">
                                        <div class="row">
                                            <div class="col-auto">1. A leading mobile game company has an application
                                                running on Elastic Beanstalk that continuously collects player-game
                                                interactions and player's behavior then feeds the data into an Amazon
                                                Kinesis stream. A second Elastic Beanstalk app generates key performance
                                                indicators (KPIs) into a DynamoDB table and powers the game leaderboard.
                                                After a few weeks, there has been a technical problem in the Kinesis
                                                data stream which resulted in data loss for your
                                                application.<br><br>Which of the following is the most efficient and
                                                most scalable option to prevent any data loss for this application?
                                            </div>
                                            <div class="col-auto"><span
                                                    class="btn btn-sm btn-primary button-category mb-1">Kinesis</span>
                                            </div>
                                        </div>
                                        <div>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div id="collapse-4888" class="accordion-collapse collapse accordion-content show "
                                aria-labelledby="heading-4888" data-bs-parent="#accordionQuestion">
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13239"
                                            disabled="" checked="">
                                        <label class="form-check-labelx" for="answers-13239">
                                            <b>Launching a third Elastic Beanstalk app that uses the Amazon Kinesis S3
                                                connector or Amazon Kinesis Data Firehose to archive the data from
                                                Kinesis into an S3 bucket</b>
                                            <br>
                                            <i>Amazon Kinesis Data Firehose is the easiest way to reliably load
                                                streaming data into data stores and analytics tools. It can capture,
                                                transform, and load streaming data into Amazon S3, Amazon Redshift,
                                                Amazon Elasticsearch Service, and Splunk, enabling near real-time
                                                analytics with existing business intelligence tools and dashboards
                                                youâ€™re already using today. It is a fully managed service that
                                                automatically scales to match the throughput of your data and requires
                                                no ongoing administration. It can also batch, compress, transform, and
                                                encrypt the data before loading it, minimizing the amount of storage
                                                used at the destination and increasing security.</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13240"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13240">
                                            Using Data Pipeline to replicate your DynamoDB tables into another region
                                            <br>
                                            <i>Data Pipeline service does not support data streams unlike Kinesis, and
                                                replicating your DynamoDB tables into another region does not solve the
                                                root cause of the data loss.</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13241"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13241">
                                            Launching a second Amazon Kinesis stream in another Availability Zone then
                                            using Data Pipeline to replicate data across Kinesis streams
                                            <br>
                                            <i>Replicating the data across Kinesis streams will only provide redundancy
                                                but will not solve the root cause of the data loss issue.</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13242"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13242">
                                            Using the second AWS Elastic Beanstalk app to store a backup of Kinesis data
                                            onto an EBS volume, and then creating snapshots from your EBS volumes
                                            <br>
                                            <i>Storing the data on EBS volumes is not a scalable solution</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="tags accordion-body">
                                </div>
                            </div>
                        </div>
                        <br>
                        <div class="accordion-item">
                            <div class="accordion-header" id="heading-4889">
                                <div style="color: rgba(0, 0, 0, 0.8);" class="accordion-button" type="button"
                                    data-bs-toggle="collapse" data-bs-target="#collapse-4889" aria-expanded="true"
                                    aria-controls="collapse-4889">
                                    <div style="display: flex;flex-direction: row;justify-content: space-between;}">
                                        <div class="row">
                                            <div class="col-auto">2. A company is developing an application that will
                                                allow biologists from around the world to submit plant genomic
                                                information and share it with other biologists. The application will
                                                expect several submissions every minute and will push about 8KB of
                                                genomic data every second to the data platform. This data needs to be
                                                processed and analyzed to provide meaningful information back to the
                                                biologists. The following are the requirements for the data
                                                platform:<br><br>- The inbound genomic data must be processed
                                                near-real-time and provide analytics.<br><br>- The received data must be
                                                stored in a flexible, parallel, and durable manner.<br><br>- After
                                                processing the data, the resulting output must be delivered to a data
                                                warehouse.<br><br>Which of the following options should the Solutions
                                                Architect implement to meet the company requirements?</div>
                                            <div class="col-auto"><span
                                                    class="btn btn-sm btn-primary button-category mb-1">Kinesis</span>
                                            </div>
                                        </div>
                                        <div>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div id="collapse-4889" class="accordion-collapse collapse accordion-content show "
                                aria-labelledby="heading-4889" data-bs-parent="#accordionQuestion">
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13243"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13243">
                                            Create a delivery stream on Amazon Kinesis Data Firehose to deliver the
                                            inbound data to an Amazon S3 bucket. Use a Kinesis client to analyze the
                                            stored data. After processing, send the results to an Amazon RDS instance
                                            <br>
                                            <i>Amazon RDS is not a suitable data warehousing solution. AWS recommends
                                                Amazon Reshift as a data warehouse solution.</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13244"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13244">
                                            Store all inbound data files directly to an Amazon S3 bucket. Use Amazon
                                            Kinesis with Amazon SQS to analyze the data stored in the S3 bucket. After
                                            processing, send the results to an Amazon Redshift cluster
                                            <br>
                                            <i>Storing files to S3 first and then sending a message to an SQS queue
                                                takes some time. This solution may not meet the near-real-time
                                                requirement. You will also have to write your own Lambda function which
                                                increases operational overhead.</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13245"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13245">
                                            Leverage Amazon API Gateway to accept the inbound data and send it to an
                                            Amazon SQS queue. Write an AWS Lambda function that will process the
                                            messages on the SQS queue. After processing, use Amazon EMR to save the
                                            results to an Amazon Redshift cluster
                                            <br>
                                            <i>It is possible to integrate API Gateway with Amazon SQS. However, the
                                                messages will be processed not in an orderly manner required for
                                                near-real-time analysis.</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13246"
                                            disabled="" checked="">
                                        <label class="form-check-labelx" for="answers-13246">
                                            <b>Create a stream in Amazon Kinesis Data Streams to collect the inbound
                                                data. Use a Kinesis client to analyze the genomic data. After
                                                processing, use Amazon EMR to save the results to an Amazon Redshift
                                                cluster</b>
                                            <br>
                                            <i>Amazon Kinesis Data Streams (KDS) is a massively scalable and durable
                                                real-time data streaming service. Your data can be made available to
                                                real-time analytics applications and then saved to Amazon Redshift for
                                                data warehousing.</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="tags accordion-body">
                                </div>
                            </div>
                        </div>
                        <br>
                        <div class="accordion-item">
                            <div class="accordion-header" id="heading-4890">
                                <div style="color: rgba(0, 0, 0, 0.8);" class="accordion-button" type="button"
                                    data-bs-toggle="collapse" data-bs-target="#collapse-4890" aria-expanded="true"
                                    aria-controls="collapse-4890">
                                    <div style="display: flex;flex-direction: row;justify-content: space-between;}">
                                        <div class="row">
                                            <div class="col-auto">3. An adventure company runs a PostgreSQL database
                                                that is used to store events from its monitoring application on its
                                                on-premises data center. The database is unable to scale enough to
                                                handle frequent write events that need to be ingested into the database.
                                                The management has tasked the solutions architect to create a hybrid
                                                solution that will utilize the existing company VPN connection to AWS.
                                                Additional requirements are as follows:<br><br>1. Leverage AWS-managed
                                                services to minimize operation overhead<br><br>2. Create a buffer that
                                                automatically scales to accommodate the events that need to be
                                                ingested<br><br>3. A visualization tool to observe near real-time events
                                                and supports creating dashboards.<br><br>4. Has support for dynamic
                                                schemas and semi-structured JSON data.<br><br>Which of the following
                                                options should the solutions architect implement to meet the company
                                                requirements? (Select TWO.)</div>
                                            <div class="col-auto"><span
                                                    class="btn btn-sm btn-primary button-category mb-1">Kinesis</span>
                                            </div>
                                        </div>
                                        <div>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div id="collapse-4890" class="accordion-collapse collapse accordion-content show "
                                aria-labelledby="heading-4890" data-bs-parent="#accordionQuestion">
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="checkbox" value="" id="answers-13247"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13247">
                                            Levering Amazon Neptune DB auto-scaling feature to reliably ingest the
                                            events. Use Neptune DB as the DB source for Amazon QuickSight to create
                                            near-real-time dashboards and visualizations
                                            <br>
                                            <i>Neptune DB is designed for graph application and loading CSV formatted
                                                data. Amazon QuickSight can directly use Neptune DB as a source.</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="checkbox" value="" id="answers-13248"
                                            disabled="" checked="">
                                        <label class="form-check-labelx" for="answers-13248">
                                            Provision an Amazon Aurora PostgreSQL DB cluster to reliably ingest the
                                            events. Use this DB as the source for Amazon QuickSight to create
                                            near-real-time dashboards and visualizations
                                            <br>
                                            <i>Amazon Aurora PostgreSQL may not be suited for ingesting semi-structured
                                                JSON or data with dynamic schemas. You will need to use a data
                                                transformer before ingesting to PostgreSQL database</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="checkbox" value="" id="answers-13249"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13249">
                                            <b>Ingest the events using Kinesis Data Firehose. Write a Lambda function to
                                                process and transform the buffered events</b>
                                            <br>
                                            <i>Kinesis Data Firehose can automatically scale to buffer the streaming
                                                events, while a Lambda function processes and transforms the events to a
                                                proper format.</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="checkbox" value="" id="answers-13250"
                                            disabled="" checked="">
                                        <label class="form-check-labelx" for="answers-13250">
                                            Use Amazon Kinesis Data Stream to reliably ingest the events. Write a Lambda
                                            function to process and transform the buffered events
                                            <br>
                                            <i>This may be possible, but since you are going to use Kinesis as a buffer,
                                                you don't need the longer-term, durable storage offered by Kinesis Data
                                                Stream. Amazon Kinesis Data Firehose has a feature to buffer data and
                                                supports data transformation in near-real-time</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="checkbox" value="" id="answers-13251"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13251">
                                            <b>Create an Amazon OpenSearch Service domain to reliably ingest the events.
                                                Leverage the OpenSearch Dashboards tool to create near-real-time
                                                dashboards and visualizations</b>
                                            <br>
                                            <i>OpenSearch Service allows you to store and search the semi-structured
                                                JSON data. It also has tools to create dashboards and
                                                visualizations.</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="tags accordion-body">
                                </div>
                            </div>
                        </div>
                        <br>
                        <div class="accordion-item">
                            <div class="accordion-header" id="heading-4891">
                                <div style="color: rgba(0, 0, 0, 0.8);" class="accordion-button" type="button"
                                    data-bs-toggle="collapse" data-bs-target="#collapse-4891" aria-expanded="true"
                                    aria-controls="collapse-4891">
                                    <div style="display: flex;flex-direction: row;justify-content: space-between;}">
                                        <div class="row">
                                            <div class="col-auto">4. A top Internet of Things (IoT) company has
                                                developed a wrist-worn activity tracker for soldiers deployed in the
                                                field. The device acts as a sensor to monitor the health and vital
                                                statistics of the wearer. It is expected that there would be thousands
                                                of devices that will send data to the server every minute and after 5
                                                years, the number will increase to tens of thousands. One of the
                                                requirements is that the application should be able to accept the
                                                incoming data, run it through ETL to store in a data warehouse, and
                                                archive the old data. The officers in the military headquarters should
                                                have a real-time dashboard to view the sensor data.<br><br>Which of the
                                                following options is the most suitable architecture to implement in this
                                                scenario?</div>
                                            <div class="col-auto"><span
                                                    class="btn btn-sm btn-primary button-category mb-1">Kinesis</span>
                                            </div>
                                        </div>
                                        <div>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div id="collapse-4891" class="accordion-collapse collapse accordion-content show "
                                aria-labelledby="heading-4891" data-bs-parent="#accordionQuestion">
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13252"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13252">
                                            Store the data directly to DynamoDB. Launch a data pipeline that starts an
                                            EMR cluster using data from DynamoDB and sends the data to S3 and Redshift
                                            <br>
                                            <i>For the collection of real-time data, AWS recommends Amazon Kinesis for
                                                ingestion. After ingestion, you can output the data into several AWS
                                                services for further processing</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13253"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13253">
                                            Store the raw data directly in an Amazon S3 bucket with a lifecycle policy
                                            to store in Glacier after a month. Register the S3 bucket as a source on AWS
                                            Lake Formation. Launch an EMR cluster access the data lake, runs it through
                                            ETL, and then output that data to Amazon Redshift
                                            <br>
                                            <i>Amazon S3 can only accept data using HTTP requests, and the data sent by
                                                IoT may be in a different format. For ingesting the data, Amazon Kinesis
                                                should be the first one to accept, process it, and store in Amazon
                                                S3.<br><br></i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13254"
                                            disabled="" checked="">
                                        <label class="form-check-labelx" for="answers-13254">
                                            <b>Send the raw data directly to Amazon Kinesis Data Firehose for processing
                                                and output the data to an S3 bucket. For archiving, create a lifecycle
                                                policy from S3 to Glacier. Use Lambda to process the data through Amazon
                                                EMR and sends the output to Amazon Redshift</b>
                                            <br>
                                            <i>Amazon Kinesis Data Firehose is a fully managed service for delivering
                                                real-time streaming data to destinations such as Amazon Simple Storage
                                                Service (Amazon S3), Amazon Redshift, Amazon OpenSearch Service, Splunk,
                                                and any custom HTTP endpoint or HTTP endpoints owned by supported
                                                third-party service providers, including Datadog, Dynatrace,
                                                LogicMonitor, MongoDB, New Relic, and Sumo Logic. Kinesis Data Firehose
                                                is part of the Kinesis streaming data platform, along with Kinesis Data
                                                Streams, Kinesis Video Streams, and Amazon Kinesis Data Analytics</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13255"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13255">
                                            Leverage Amazon Athena to accept the incoming data and store them using
                                            DynamoDB. Setup a cron job that takes data from the DynamoDB table and sends
                                            it to an Amazon EMR cluster for ETL, then outputs the result to Amazon
                                            Redshift
                                            <br>
                                            <i>Amazon Athena is a query service to query data and analyze big data, and
                                                not suitable for ingesting real-time IoT data</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="tags accordion-body">
                                </div>
                            </div>
                        </div>
                        <br>
                        <div class="accordion-item">
                            <div class="accordion-header" id="heading-4892">
                                <div style="color: rgba(0, 0, 0, 0.8);" class="accordion-button" type="button"
                                    data-bs-toggle="collapse" data-bs-target="#collapse-4892" aria-expanded="true"
                                    aria-controls="collapse-4892">
                                    <div style="display: flex;flex-direction: row;justify-content: space-between;}">
                                        <div class="row">
                                            <div class="col-auto">5. A financial services company receives a regular
                                                data feed from its credit card servicing partner. Approximately 5,000
                                                records are sent every 15 minutes in plaintext, delivered over HTTPS
                                                directly into an Amazon S3 bucket with server-side encryption. This feed
                                                contains sensitive credit card primary account number (PAN) data. The
                                                company needs to automatically mask the PAN before sending the data to
                                                another S3 bucket for additional internal processing. The company also
                                                needs to remove and merge specific fields, and then transform the record
                                                into JSON format. Additionally, extra feeds are likely to be added in
                                                the future, so any design needs to be easily expandable.<br>Which
                                                solutions will meet these requirements?</div>
                                        </div>
                                        <div>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div id="collapse-4892" class="accordion-collapse collapse accordion-content show "
                                aria-labelledby="heading-4892" data-bs-parent="#accordionQuestion">
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13256"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13256">
                                            Invoke an AWS Lambda function on file delivery that extracts each record and
                                            writes it to an Amazon SQS queue. Invoke another Lambda function when new
                                            messages arrive in the SQS queue to process the records, writing the results
                                            to a temporary location in Amazon S3. Invoke a final Lambda function once
                                            the SQS queue is empty to transform the records into JSON format and send
                                            the results to another S3 bucket for internal processing.
                                            <br>
                                            <i>This option requires a lot of opeartions when multi Lambda functions and
                                                SQS queues expanding in the future</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13257"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13257">
                                            Invoke an AWS Lambda function on file delivery that extracts each record and
                                            writes it to an Amazon SQS queue. Configure an AWS Fargate container
                                            application to automatically scale to a single instance when the SQS queue
                                            contains messages. Have the application process each record, and transform
                                            the record into JSON format. When the queue is empty, send the results to
                                            another S3 bucket for internal processing and scale down the AWS Fargate
                                            instance.
                                            <br>
                                            <i>The requirement is quite straight-forward, and it does not seem to have
                                                much data to process. So using Fargate can be costly</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13258"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13258">
                                            <b>Create an AWS Glue crawler and custom classifier based on the data feed
                                                formats and build a table definition to match. Invoke an AWS
                                                Lambda function on file delivery to start an AWS Glue ETL job to
                                                transform the entire record according to the processing and
                                                transformation requirements. Define the output format as JSON. Once
                                                complete, have the ETL job send the results to another S3 bucket for
                                                internal processing.</b>
                                            <br>
                                            <i>Glue is fit for this scenario because Glue is focus on ETL job. The
                                                process is quite simple but can be scaled in the future.</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13259"
                                            disabled="" checked="">
                                        <label class="form-check-labelx" for="answers-13259">
                                            Create an AWS Glue crawler and custom classifier based upon the data feed
                                            formats and build a table definition to match. Perform an Amazon Athena
                                            query on file delivery to start an Amazon EMR ETL job to transform the
                                            entire record according to the processing and transformation requirements.
                                            Define the output format as JSON. Once complete, send the results to another
                                            S3 bucket for internal processing and scale down the EMR cluster.
                                            <br>
                                            <i>EMR can be used in this scenario. However, EMR is often used in a complex
                                                scenario, which requires lots of process. And it is also costly.</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="tags accordion-body">
                                </div>
                            </div>
                        </div>
                        <br>
                        <div class="accordion-item">
                            <div class="accordion-header" id="heading-4893">
                                <div style="color: rgba(0, 0, 0, 0.8);" class="accordion-button" type="button"
                                    data-bs-toggle="collapse" data-bs-target="#collapse-4893" aria-expanded="true"
                                    aria-controls="collapse-4893">
                                    <div style="display: flex;flex-direction: row;justify-content: space-between;}">
                                        <div class="row">
                                            <div class="col-auto">6. A company is running an application in the AWS
                                                Cloud. The application collects and stores a large amount of
                                                unstructured data in an Amazon S3 bucket. The S3 bucket contains several
                                                terabytes of data and uses the S3 Standard storage class. The data
                                                increases in size by several gigabytes every day. The company needs to
                                                query and analyze the data. The company does not access data that is
                                                more than 1 year old. However, the company must<br>retain all the data
                                                indefinitely for compliance reasons.<br>Which solution will meet these
                                                requirements MOST cost-effectively?</div>
                                        </div>
                                        <div>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div id="collapse-4893" class="accordion-collapse collapse accordion-content show "
                                aria-labelledby="heading-4893" data-bs-parent="#accordionQuestion">
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13260"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13260">
                                            Use S3 Select to query the data. Create an S3 Lifecycle policy to transition
                                            data that is more than 1 year old to S3 Glacier Deep Archive.
                                            <br>
                                            <i>S3 Select only good for the scenario where the query happens infrequently
                                                and the amount of data is small. In this scenario, the data increase by
                                                gigabytes, so Glue Data Catalog is better in this case</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13261"
                                            disabled="" checked="">
                                        <label class="form-check-labelx" for="answers-13261">
                                            Use Amazon Redshift Spectrum to query the data. Create an S3 Lifecycle
                                            policy to transition data that is more than 1 year old 10 S3 Glacier Deep
                                            Archive.
                                            <br>
                                            <i>Redshift Spectrum is used to query data as exabytes, (very large amount
                                                of data). If we use in this case, this may not be an cost optimize
                                                option</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13262"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13262">
                                            <b>Use an AWS Glue Data Catalog and Amazon Athena to query the data. Create
                                                an S3 Lifecycle policy to transition data that is more than 1
                                                year old to S3 Glacier Deep Archive.</b>
                                            <br>
                                            <i>This solution allows you to use Amazon Athena and the AWS Glue Data
                                                Catalog to query and analyze the data in an S3 bucket. Amazon Athena is
                                                a serverless, interactive query service that allows you to analyze data
                                                in S3 using SQL. The AWS Glue Data Catalog is a managed metadata
                                                repository that can be used to store and retrieve table definitions for
                                                data stored in S3. Together, these services can provide a cost-effective
                                                way to query and analyze large amounts of unstructured data.
                                                Additionally, by using an S3 Lifecycle policy to transition data that is
                                                more than 1 year old to<br>S3 Glacier Deep Archive, you can retain the
                                                data indefinitely for compliance reasons while also reducing storage
                                                costs.</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13263"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13263">
                                            Use Amazon Redshift Spectrum to query the data. Create an S3 Lifecycle
                                            policy to transition data that is more than 1 year old to S3
                                            Intelligent-Tiering.
                                            <br>
                                            <i>Redshift Spectrum is used to query data as exabytes, (very large amount
                                                of data). If we use in this case, this may not be a cost-optimized
                                                option</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="tags accordion-body">
                                </div>
                            </div>
                        </div>
                        <br>
                        <div class="accordion-item">
                            <div class="accordion-header" id="heading-4894">
                                <div style="color: rgba(0, 0, 0, 0.8);" class="accordion-button" type="button"
                                    data-bs-toggle="collapse" data-bs-target="#collapse-4894" aria-expanded="true"
                                    aria-controls="collapse-4894">
                                    <div style="display: flex;flex-direction: row;justify-content: space-between;}">
                                        <div class="row">
                                            <div class="col-auto">7. A company has purchased appliances from different
                                                vendors. The appliances all have IoT sensors. The sensors send status
                                                information in the vendors' proprietary formats to a legacy application
                                                that parses the information into JSON. The parsing is simple, but each
                                                vendor has a unique format. Once daily, the application parses all the
                                                JSON records and stores the records in a relational database for
                                                analysis. The company needs to design a new data analysis solution that
                                                can deliver faster and optimize costs. Which solution will meet these
                                                requirements?</div>
                                        </div>
                                        <div>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div id="collapse-4894" class="accordion-collapse collapse accordion-content show "
                                aria-labelledby="heading-4894" data-bs-parent="#accordionQuestion">
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13264"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13264">
                                            Connect the IoT sensors to AWS IoT Core. Set a rule to invoke an AWS Lambda
                                            function to parse the information and save a .csv file to Amazon. S3 Use AWS
                                            Glue to catalog the files. Use Amazon Athena and Amazon QuickSight for
                                            analysis.
                                            <br>
                                            <i>This option is acceptable for this case. Using Athena and S3, we can form
                                                a cost optimized solution</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13265"
                                            disabled="" checked="">
                                        <label class="form-check-labelx" for="answers-13265">
                                            Migrate the application server to AWS Fargate, which will receive the
                                            information from IoT sensors and parse the information into a relational
                                            format. Save the parsed information to Amazon Redshlft for analysis.
                                            <br>
                                            <i>The parsing is simple, so we should not use RedShift in this case, cause
                                                it will cost too much.</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13266"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13266">
                                            Create an AWS Transfer for SFTP server. Update the IoT sensor code to send
                                            the information as a .csv file through SFTP to the server. Use AWS Glue to
                                            catalog the files. Use Amazon Athena for analysis.
                                            <br>
                                            <i>IoT Sensor cannot use FTP/SFTP to send file to server</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13267"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13267">
                                            Use AWS Snowball Edge to collect data from the IoT sensors directly to
                                            perform local analysis. Periodically collect the data into Amazon Redshift
                                            to perform global analysis.
                                            <br>
                                            <i>Cannot use Snowball Edge to collect data from IoT</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="tags accordion-body">
                                </div>
                            </div>
                        </div>
                        <br>
                        <div class="accordion-item">
                            <div class="accordion-header" id="heading-4895">
                                <div style="color: rgba(0, 0, 0, 0.8);" class="accordion-button" type="button"
                                    data-bs-toggle="collapse" data-bs-target="#collapse-4895" aria-expanded="true"
                                    aria-controls="collapse-4895">
                                    <div style="display: flex;flex-direction: row;justify-content: space-between;}">
                                        <div class="row">
                                            <div class="col-auto">8. A startup develops Internet-Of-Things (IoT) devices
                                                that provide health monitoring for dogs and cats which is integrated
                                                into their collars. The startup has an engineering team to build a smart
                                                pet collar that collects biometric information of the pet every second
                                                and then sends it to a web portal through a POST API request. The
                                                Solutions Architect has been tasked to set up the API services and the
                                                web portal that will accept and process the biometric data as well as
                                                provide complete trends and health reports to pet owners around the
                                                globe. The portal should be highly durable, available, and scalable with
                                                an additional feature for showing real-time biometric data analytics and
                                                monitoring.<br><br>Which of the following is the best architecture that
                                                the Solutions Architect should implement to meet the above requirement?
                                            </div>
                                        </div>
                                        <div>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div id="collapse-4895" class="accordion-collapse collapse accordion-content show "
                                aria-labelledby="heading-4895" data-bs-parent="#accordionQuestion">
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13268"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13268">
                                            1. Create an Amazon S3 bucket to collect the incoming biometric data from
                                            the smart pet collar.
                                            2. Use Amazon Data Pipeline to run a data analysis task in the S3 bucket
                                            every day.
                                            3. Use Amazon Redshift as the online analytic processing (OLAP) database for
                                            the web portal.
                                            <br>
                                            <i>S3, Data Pipeline, and Redshift do not provide real-time data
                                                analytics:</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13269"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13269">
                                            1. Create an Amazon SQS queue to collect the incoming biometric data.
                                            2. Analyze the data from SQS with Amazon Kinesis.
                                            3. Store the results to an Amazon RDS for MySQL database.
                                            <br>
                                            <i>SQS queue is not appropriate to use to accept all of the incoming
                                                biometric data</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13270"
                                            disabled="" checked="">
                                        <label class="form-check-labelx" for="answers-13270">
                                            <b>1. Use Amazon Kinesis Data Streams to collect the incoming biometric
                                                data.
                                                2. Analyze the data using Amazon Kinesis and show the results in a
                                                real-time dashboard.
                                                3. Set up a simple data aggregation process and pass the results to
                                                Amazon S3.
                                                4. Store the data to Amazon Redshift, configured with automated backups,
                                                to handle complex analytics.</b>
                                            <br>
                                            <i>Kinesis Data Streams can be used to collect log and event data from
                                                sources such as servers, desktops, and mobile devices. You can then
                                                build Kinesis Applications to continuously process the data, generate
                                                metrics, power live dashboards, and emit aggregated data into stores
                                                such as Amazon S3.<br><br>You can have your Kinesis Applications run
                                                real-time analytics on high frequency event data such as sensor data
                                                collected by Kinesis Data Streams, which enables you to gain insights
                                                from your data at a frequency of minutes instead of hours or days</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13271"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13271">
                                            1. Launch an Amazon Elastic MapReduce instance to collect the incoming
                                            biometrics data.
                                            2. Use Amazon Kinesis to analyze the data.
                                            3. Save the results to an Amazon DynamoDB table.
                                            <br>
                                            <i>Elastic MapReduce is not suitable for collecting real-time data</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="tags accordion-body">
                                </div>
                            </div>
                        </div>
                        <br>
                        <div class="accordion-item">
                            <div class="accordion-header" id="heading-4896">
                                <div style="color: rgba(0, 0, 0, 0.8);" class="accordion-button" type="button"
                                    data-bs-toggle="collapse" data-bs-target="#collapse-4896" aria-expanded="true"
                                    aria-controls="collapse-4896">
                                    <div style="display: flex;flex-direction: row;justify-content: space-between;}">
                                        <div class="row">
                                            <div class="col-auto">9. A leading media company has a hybrid architecture
                                                where its on-premises data center is connected to AWS via a Direct
                                                Connect connection. They also have a repository of over 50-TB digital
                                                videos and media files. These files are stored on their on-premises tape
                                                library and are used by their Media Asset Management (MAM) system. Due
                                                to the sheer size of their data, they want to implement an automated
                                                catalog system that will enable them to search their files using facial
                                                recognition. A catalog will store the faces of the people who are
                                                present in these videos including a still image of each person.
                                                Eventually, the media company would like to migrate these media files to
                                                AWS including the MAM video contents.<br><br>Which of the following
                                                options provides a solution which uses the LEAST amount of ongoing
                                                management overhead and will cause MINIMAL disruption to the existing
                                                system?</div>
                                        </div>
                                        <div>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div id="collapse-4896" class="accordion-collapse collapse accordion-content show "
                                aria-labelledby="heading-4896" data-bs-parent="#accordionQuestion">
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13272"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13272">
                                            Request for an AWS Snowball Storage Optimized device to migrate all of the
                                            media files from the on-premises library into Amazon S3. Provision a large
                                            EC2 instance and allow it to access the S3 bucket. Install an open-source
                                            facial recognition tool on the instance like OpenFace or OpenCV. Process the
                                            media files to retrieve the metadata and push this information into the MAM
                                            solution. Lastly, copy the media files to another S3 bucket
                                            <br>
                                            <i>This entails a lot of ongoing management overhead instead of just using
                                                Amazon Rekognition. Moreover, it is more suitable to use the AWS Storage
                                                Gateway service rather than an EBS Volume.</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13273"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13273">
                                            Set up a tape gateway appliance on-premises and connect it to your AWS
                                            Storage Gateway. Configure the MAM solution to fetch the media files from
                                            the current archive and push them into the tape gateway to be stored in
                                            Amazon Glacier. Using Amazon Rekognition, build a collection from the
                                            catalog of faces. Utilize a Lambda function which invokes the Rekognition
                                            Javascript SDK to have Amazon Rekognition process the video directly from
                                            the tape gateway in real-time, retrieve the required metadata, and push the
                                            metadata into the MAM solution
                                            <br>
                                            <i>You can't directly fetch the media files from your tape gateway in real
                                                time since this is backed up using Glacier. Tape gateway in the AWS
                                                Storage Gateway service is primarily used as an archive solution.</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13274"
                                            disabled="" checked="">
                                        <label class="form-check-labelx" for="answers-13274">
                                            Use Amazon Kinesis Video Streams to set up a video ingestion stream and with
                                            Amazon Rekognition, build a collection of faces. Stream the media files from
                                            the MAM solution into Kinesis Video Streams and configure the Amazon
                                            Rekognition to process the streamed files. Launch a stream consumer to
                                            retrieve the required metadata, and push the metadata into the MAM solution.
                                            Finally, configure the stream to store the files in an S3 bucket
                                            <br>
                                            <i>You won't be able to connect your tape gateway directly to your Kinesis
                                                Video Streams service. You need to use AWS Storage Gateway first.</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13275"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13275">
                                            <b>Integrate the file system of your local data center to AWS Storage
                                                Gateway by setting up a file gateway appliance on-premises. Utilize the
                                                MAM solution to extract the media files from the current data store and
                                                send them into the file gateway. Build a collection using Amazon
                                                Rekognition by populating a catalog of faces from the processed media
                                                files. Use an AWS Lambda function to invoke Amazon Rekognition
                                                Javascript SDK to have it fetch the media file from the S3 bucket which
                                                is backing the file gateway, retrieve the needed metadata, and finally,
                                                persist the information into the MAM solution</b>
                                            <br>
                                            <i></i>
                                        </label>
                                    </div>
                                </div>
                                <div class="tags accordion-body">
                                </div>
                            </div>
                        </div>
                        <br>
                        <div class="accordion-item">
                            <div class="accordion-header" id="heading-4897">
                                <div style="color: rgba(0, 0, 0, 0.8);" class="accordion-button" type="button"
                                    data-bs-toggle="collapse" data-bs-target="#collapse-4897" aria-expanded="true"
                                    aria-controls="collapse-4897">
                                    <div style="display: flex;flex-direction: row;justify-content: space-between;}">
                                        <div class="row">
                                            <div class="col-auto">10. A leading online media company runs a popular
                                                sports news website. The solutions architect has been tasked to analyze
                                                each web visitor's clickstream data on the website to populate user
                                                analytics, which gives insights about the sequence of pages and
                                                advertisements the visitor has clicked. The data will be processed in
                                                real-time which will then transform the page layout as the visitors
                                                click through the web portal to increase user engagement and
                                                consequently, increase the revenue for the company.<br><br>Which of the
                                                following options should the solutions architect implement to meet the
                                                above requirements?</div>
                                        </div>
                                        <div>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div id="collapse-4897" class="accordion-collapse collapse accordion-content show "
                                aria-labelledby="heading-4897" data-bs-parent="#accordionQuestion">
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13276"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13276">
                                            Log clicks in weblogs by URL and store it in Amazon S3, and then analyze
                                            with Elastic MapReduce
                                            <br>
                                            <i>EMR services do not have the capacity to analyze real-time streaming
                                                data</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13277"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13277">
                                            Publish the web clicks to AWS IoT Analytics. Run custom analysis, SQL
                                            queries and apply machine learning to generate relevant reports regarding
                                            user behavior
                                            <br>
                                            <i>IoT do not have the capacity to analyze real-time streaming data</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13278"
                                            disabled="" checked="">
                                        <label class="form-check-labelx" for="answers-13278">
                                            <b>Push web clicks by session to Amazon Kinesis and analyzing behavior using
                                                Amazon Kinesis workers</b>
                                            <br>
                                            <i>Amazon Kinesis, you can ingest real-time data such as video, audio,
                                                application logs, website clickstreams, and IoT telemetry data for
                                                machine learning, analytics, and other applications. Amazon Kinesis
                                                enables you to process and analyze data as it arrives and responds
                                                instantly instead of having to wait until all your data is collected
                                                before the processing can begin</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="accordion-body">
                                    <div class="form-check">
                                        <input class="form-check-input" type="radio" value="" id="answers-13279"
                                            disabled="">
                                        <label class="form-check-labelx" for="answers-13279">
                                            Publish web clicks by session to an Amazon SQS queue and periodically drain
                                            these events to Amazon RDS then analyze with SQL.
                                            <br>
                                            <i>SQS services do not have the capacity to analyze real-time streaming
                                                data</i>
                                        </label>
                                    </div>
                                </div>
                                <div class="tags accordion-body">
                                </div>
                            </div>
                        </div>
                        <br>
                    </div>

                </div>
                <div class="col-md-2"></div>
            </div>
        </div>
    </div>

</body>

</html>